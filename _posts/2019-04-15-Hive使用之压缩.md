---
title: Hive使用之压缩
tags:
  - 大数据
  - Hive
categories:
  - 大数据
---

## 压缩的好处和坏处

- 好处
  - 减少磁盘空间使用量
  - 降低磁盘IO和网络IO
  - 加快数据在磁盘和网络中的传输速度，从而提高系统的处理速度
- 坏处
  - 在读取数据的时候需要先解压，加重CPU负载

## 压缩格式对比

| 压缩格式 | 工具  | 算法    | 扩展名   | 是否支持分片                       | Hadoop编码/解码器                          |
| -------- | ----- | ------- | -------- | ---------------------------------- | ------------------------------------------ |
| DEFLATE  | N/A   | DEFLATE | .deflate | NO                                 | org.apache.hadoop.io.compress.DefaultCodec |
| gzip     | gzip  | DEFLATE | .gz      | NO                                 | org.apache.hadoop.io.compress.GzipCodec    |
| bzip2    | bzip2 | bzip2   | .bz2     | Yes                                | org.apache.hadoop.io.compress.BZip2Codec   |
| LZO      | Lzop  | LZO     | .lzo     | 默认不支持,需要设置index来支持分片 | com.hadoop.compress.lzo.LzoCodec           |
| LZ4      | N/A   | LZ4     | .lz4     | NO                                 | org.apache.hadoop.io.compress.Lz4Codec     |
| Snappy   | N/A   | Snappy  | .snappy  | NO                                 | org.apache.hadoop.io.compress.SnappyCodec  |

**压缩比对比**

![压缩比对比](https://s2.ax1x.com/2019/04/20/ECxpwj.png)

**压缩时间对比**

![压缩时间对比](https://s2.ax1x.com/2019/04/20/ECxSmQ.png)

**两张图对比可以看出压缩比和压缩速度成反比**
比如：BZIP2压缩效果最好，但是压缩解压缩时间最慢

### 常用压缩格式的优缺点

#### GZIP

优点:

- 压缩比较高
- hadoop本身就支持
- 大部分linux系统自带有gzip命令

缺点

- 不支持分片

#### LZO

优点：

- 合理的压缩比
- 支持split
- 是hadoop中最流行的压缩格式
- 支持hadoop native库
- 需要在linux中安装lzop命令

缺点

- 压缩率比gzip要低
- hadoop本身不支持，需要安装
- lzo虽然支持split，但需要对lzo文件建索引，否则hadoop也是会把lzo文件看成一个普通文件

#### SNAPPY

优点:

- 压缩速度快
- 支持hadoop native 库

缺点:

- 不支持split
- 压缩比低
- hadoop不支持，需要编译
- linux系统下没有对应的命令

#### GZIP2

优点:

- 支持split;
- 具有很高的压缩性
- hadoop本身支持,但不支持native 库
- 在linux下自带bzip2命令，使用方便

缺点:

- 压缩解压速度慢
- 不支持native



## 如何选择合适的压缩格式

下图是一个通用的Hadoop中数据处理流程

![1555342721985](https://s2.ax1x.com/2019/04/15/AveoCR.png)

1. 在ETL原始数据中是可以压缩的并且要支持分片，如果不支持分片，那么只会有一个MAP TASK来处理这个数据。
2. MAP出来的结果是可以压缩的,这一过程中出来的数据时马上就要被shuffle的，所以没必要采用那么高的压缩比，强调速度快。
3. Reduce作业结束后的输出可以压缩，这一过程结束后可以分为两种不同的场景。
   - Reduce作业的输出结果作为下一作业的输入，则要采用合理的压缩比并且要支持分片，如果不支持分片那么也会造成后面的作业只有一个MAP TASK来处理。
   - Reduce作业的输出结果作为归档或者是冷数据，即以后很少会使用到这个数据，可以采用高压缩比来节省磁盘空间。

## 压缩在MapReduce中的应用

### 配置文件配置支持压缩

Hadoop core-site.xml

```xml
<property>
	<name>io.compression.codecs</name>
	<value>
		org.apache.hadoop.io.compress.GzipCodec,
		org.apache.hadoop.io.compress.DefaultCodec,
		org.apache.hadoop.io.compress.BZip2Codec
	</value>
</property>

```



mapred-site.xml

```xml
<!-- mapreduce.output.fileoutputformat.compress.codec 是Reduce阶段的输出压缩格式
     其默认值为org.apache.hadoop.io.compress.DefaultCodec
	 MAP阶段的压缩配置项为
	 mapreduce.map.output.compress 默认值false
	 mapreduce.map.output.compress.codec 默认值org.apache.hadoop.io.compress.DefaultCodec
-->
<property>   
	<name>mapreduce.output.fileoutputformat.compress</name>
	<value>true</value>
</property>
<property>
	<name>mapreduce.output.fileoutputformat.compress.codec</name>
	<value>org.apache.hadoop.io.compress.BZip2Codec</value>
</property>
```

### 测试是否支持压缩

```shell
## 使用简单的wordcount做测试
## 
shell> cat >> test <<EOF
hello world hello
hello world welcome
hello
EOF
shell> hadoop  fs -mkdir -p /test/hadoop/input
shell> hadoop  fs -put test /test/hadoop/input/
shell> hadoop jar hadoop-mapreduce-examples-2.6.0-cdh5.7.0.jar wordcount /test/hadoop/input/test /test/hadoop/output-wc
## 执行完成后查看
##
shell> hadoop fs -ls /test/hadoop/output-wc
-rw-r--r--   1 root supergroup          0 2019-04-15 04:12 /test/hadoop/output-wc/_SUCCESS
-rw-r--r--   1 root supergroup         61 2019-04-15 04:12 /test/hadoop/output-wc/part-r-00000.bz2
## 看到输出结果带有后缀.bz2就是已经成功的压缩了
## 当然这个文件是可以查看的
shell> hadoop fs -text /test/hadoop/output-wc/part-r-00000.bz2
## 注意这里前两句INFO 信息,他是先加载了native-bzip2再解压缩的
19/04/16 00:12:56 INFO bzip2.Bzip2Factory: Successfully loaded & initialized native-bzip2 library system-native
19/04/16 00:12:56 INFO compress.CodecPool: Got brand-new decompressor [.bz2]
hello	4
welcome	1
world	2
```

## 压缩在Hive中的应用

先来看不采用压缩的方式

```shell
hive> create table page_views(
track_time string,
url string,
session_id string,
referer string,
ip string,
end_user_id string,
city_id string
) row format delimited fields terminated by '\t';
## 预先准备好page_views.dat 数据
hive> load data local inpath '/root/data/page_views.dat' overwrite into table page_views;
## 在Hadoop上查看数据大小
shell> hadoop fs -du -s -h /user/hive/warehouse/page_views
18.1 M  18.1 M  /user/hive/warehouse/page_views
## 原始大小18.1M

```

**使用BZip2压缩**

```shell
## 首先设置压缩格式
hive> set hive.exec.compress.output=true;
hive> set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.BZip2Codec;
hive> create table page_views_bzip2 as select * from page_views;
## 在Hadoop上查看数据大小
shell> hadoop fs -du -s -h /user/hive/warehouse/page_views_bzip2
3.6 M  3.6 M  /user/hive/warehouse/page_views_bzip2

```

**使用GZip压缩**

```shell
## 设置压缩格式
hive> set hive.exec.compress.output=true;
hive> set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec;
hive> create table page_views_gzip as select * from page_views;
## 在Hadoop上查看数据大小
shell> hadoop fs -du -s -h /user/hive/warehouse/page_views_gzip
5.3 M  5.3 M  /user/hive/warehouse/page_views_gzip
```

