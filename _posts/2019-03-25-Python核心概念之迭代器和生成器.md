---
title: Python核心概念之迭代器和生成器
tags:
  - Python3
categories:
  - Python
---

在了解 Python 的数据结构时，容器(container)、可迭代对象(iterable)、迭代器(iterator)、生成器(generator)、列表/集合/字典推导式(list,set,dict comprehension)众多概念参杂在一起，让我在初学时一头雾水，我将用一篇文章试图将这些概念以及它们之间的关系捋清楚 。

### 容器(container)

容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用 `in` , `not in` 关键字判断元素是否包含在容器中。通常这类数据结构把所有的元素存储在内存中（也有一些特例并不是所有的元素都放在内存）。在 Python 中，常见的容器对象有：

- list, deque, ….
- set, frozensets, ….

- dict, defaultdict, OrderedDict, Counter, ….
- tuple, namedtuple, …
- str 

对于容器，可以很直观地想象成多个元素在一起的单元；而不同容器的区别，正是在于内部数据结构的实现方法



### 可迭代对象

所有的容器都是可迭代的（iterable）。此外还有更多的对象同样也是 `Iterable` 对象，比如处于打开状态的 files，sockets 等等。

这里的迭代，和枚举不完全一样。

举个例子来说明; 你去买苹果，但商家并不会告诉你库存有多少，每次你去买苹果的时候，只需要告诉商家，我要一个苹果，然后商家采取行为: 要么给你一个苹果，要么告诉你苹果卖完了，你并不需要知道商家的仓库里有多少苹果。

我们可以用`isinstance()`判断一个对象是不是可迭代（Iterable）的对象

```python
>>> from collections import Iterable
>>> isinstance([], Iterable)
True
>>> isinstance({}, Iterable)
True
>>> isinstance('abc', Iterable)
True
>>> isinstance((x for x in range(10)), Iterable)
True
>>> isinstance(100, Iterable)
False
```

迭代器内部持有一个状态，该状态用于记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。迭代器有一种具体的迭代器类型，比如 `list_iterator`，`set_iterator`。

可迭代对象都有 `x.__iter__` 和 `iter(x)` 方法，这两个方法本质一样，都会返回一个迭代器。能直接作用于 `for` 循环的对象统称为可迭代对象，要想可迭代，内部必须有一个 `__iter__` 方法。

迭代器还提供了一个 next 的方法。调用这个方法后，要么得到这个容器的下一个对象，要么得到一个 StopIteration 的错误。我们不需要像列表一样指定元素的索引，因为字典和集合这样的容器并没有索引一说。比如，字典采用哈希表实现，那么我们就只需要知道，next 函数可以不重复不遗漏地一个一个拿到所有元素即可。

#### for 循环语句的本质

当你在写:

```python
x = [1,2,3]
for e in x:
    print(e)
```

实际上`for`循环本质上做了三件事

- 调用`iter()`方法，将可迭代的对象转为迭代器,即：iter(x)
- 不断地调用next()方法，返回迭代器中的下一个元素的值
- 处理StopIteration异常

因此上述的例子完全等价于:

```python
# 获得迭代器对象
x = [1, 2, 3]
it = iter(x)
# 循环
while True:
    try:
        #获取下一个元素的值
        elem = next(it)
        print(elem)
    except StopIteration:
        #遇到StopIteration 就退出循环
        break    
```

### 迭代器

迭代器(iterator)是一个带状态的对象，同时满足下列两个条件的对象都是迭代器：

**条件1：**有\_\_iter\_\_()方法：等同于iter(),如果对象本身就是迭代器对象，则返回对象本身

```python
>>> L = [1,2,3,4]
>>> print(L.__iter__())
<listiterator object at 0x7f8cd80ec1d0>
>>> print(iter(L))
<listiterator object at 0x7f8cd80ec1d0>

X = iter(L)
>>> print(X.__iter__())
<listiterator object at 0x7f8cd80ec1d0>
>>> print(iter(X))
<listiterator object at 0x7f8cd80ec1d0>
```

**条件2:**有 `__next__()` 方法：等同于 `next()` ，返回容器中的下一个值，如果容器中没有更多元素了，则抛出 `StopIteration` 异常

```python
>>> L = [1,2,3,4]
>>> X = iter(L)
>>> type(X)
<class 'list_iterator'>
>>> next(X)
1
>>> next(X)
2
>>> next(X)
3
>>> next(X)
4
>>> next(X)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
```

在迭代器中每次调用 `next()` 方法的时候做两件事

- 为下一次调用 `next()` 方法修改状态
- 为当前这次调用生成返回结果

### 生成器

通过列表生成式，可以直接创建一个列表。但是受到内存限制，列表容量肯定是有限的。而且创建一个包含 100 万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。

所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的 list，从而节省大量的空间。在 Python 中这种一边循环一边计算的机制，称为生成器（generator）。

#### 生成器表达式

创建生成器的第一种方法很简单，只要把一个列表生成式的 `[]` 改成 `()`，就创建了一个 generator，生成器表达式是列表生成式的生成器版本，看起来像列表生成式，但是它返回的是一个生成器对象而不是列表对象：

```python
>>> L = [x * x for x in range(5)]
>>> L
[0, 1, 4, 9, 16]
>>> g = (x * x for x in range(5))
>>> g
<generator object <genexpr> at 0x012967E0>
```

创建 `L` 和 `g` 的区别仅在于最外层的 `[]` 和 `()`，`L` 是一个 list 对象，而 `g` 是一个 generator 对象，我们可以直接打印出 list 的每一个元素，但怎么打印出 generator 的每一个元素呢？

上述例子中，列表生成式相当于做好的 5 盘菜，什么时候想吃就什么时候吃，数据都都在内存空间，什么时候想调用就调用，但是比较占空间；而生成器相当于一位厨师，现在什么菜都没有，当你想吃第一道菜的时候就可以叫厨师做出来，以此类推。如果不吃，数据永远不会生成，不占内存空间，但是算法决定了必须从第一盘菜开始吃，只有在前 9 盘菜吃完才能吃最后一盘，所以如果要打印出 generator 的每一个元素，可以通过 `next()` 函数不断地获得 generator 的下一个返回值：

```python
>>> next(g)
0
>>> next(g)
1
>>> next(g)
4
>>> next(g)
9
>>> next(g)
16
>>> next(g)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
```

generator 非常强大。如果推算的算法比较复杂，用生成器表达式的 `for` 循环无法实现的时候，还可以用函数来实现。 比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：

```python
1, 1, 2, 3, 5, 8, 13, 21, 34, ...
```

斐波拉契数列用列表生成式写不出来，但是用函数把它打印出来却很容易

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

def fib(max):
    n,prev,curr = 0, 0, 1
    while n < max:
        print(curr)
        prev,curr = curr, prev + curr
        n += 1
    return 'Done'

print(fib(5))
```

#### yield关键字

生成器其实是一种特殊的迭代器，不过这种迭代器更加优雅。它不需要再像上面一样写 `iter()` 和 `next()` 方法了，只需要一个 `yiled` 关键字。 **生成器一定是迭代器**（反之不成立），因此任何生成器也是以一种懒加载的模式生成值。

仔细观察，可以看出 `fib` 函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似 generator。 也就是说上面的函数和 generator 仅差一步之遥。要把 `fib` 函数变成 generator，只需要把 `print(curr)` 改为 `yield curr` 就可以了：

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

def fib(max):
    n,prev,curr = 0, 0, 1
    while n < max:
        yield curr
        prev,curr = curr, prev + curr
        n += 1
    return 'Done'

f = fib(5)
print(f)
```

这就是定义 generator 的另一种方法。如果一个函数定义中包含 `yield` 关键字，那么这个函数就不再是一个普通函数，而是一个 generator 。上述代码执行的结果为：

```python
<generator object fib at 0x7f8409996840>
```

当执行 `f=fib(5)` 返回的是一个生成器对象，此时函数体中的代码并不会执行，只有显示或隐示地调用 `next()` 的时候才会真正执行里面的代码。将 `print(f)` 改为 `print(list(f))` 后，`list()` 方法就会隐式地调用 `next()` ，并得到我们所期望的结果：

```python
[1, 1, 2, 3, 5]
```

把函数改成 generator 后，我们基本上从来不会用 `next()`来获取下一个返回值，而是直接使用 `for` 循环来迭代：

```python
for n in fib(5):
    print(n)
```

generator 和函数的执行流程不一样。函数是顺序执行，遇到 `return` 语句或者最后一行函数语句就返回。而变成 generator 的函数，在每次调用 `next()` 的时候才执行，遇到 `yield` 语句才返回，再次执行时从上次返回的 `yield` 语句处继续执行。

举个简单的例子，定义一个 generator，依次返回数字 1，3，5：

```python
def odd():
    print("Step 1:")
    yield 1
    print("Step 2:")
    yield 3
    print("Step 3:")
    yield 5
```

调用该 generator 时，首先要生成一个 generator 对象，然后用 `next()` 函数不断获得下一个返回值：

```python
>>> o = odd()
>>> next(o)
Step 1:
1
>>> next(o)
Step 2:
3
>>> next(o)
Step 3:
5
>>> next(o) 
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
>>> 
```

可以看到 `odd` 不是普通函数，而是 generator 。在代码执行过程中只要遇到 `yield` 就中断，下次又继续执行。执行 3 次 `yield` 后，已经没有 `yield` 可以执行了，所以第 4 次调用 `next(o)` 就报错。

生成器在 Python 中是一个非常强大的编程结构，可以用更少地使用中间变量写流式代码，此外，相比其它容器对象它更能节省内存和 CPU，当然它可以用更少的代码来实现相似的功能。现在就可以动手重构你的代码了，但凡看到类似：

```python
def something():
    result = []
    for x in ...:
        result.append(x)
    return result
```

都可以用生成器函数来代替

```python
def something():
    result = []
    for x in ...:
        result.append(x)
    yield result
```

如果直接对文件对象调用 `read()` 和 `readlines()` 方法，会导致不可预测的内存占用。好的方法是利用固定长度的缓冲区来不断读取文件内容。通过 `yield`，我们不再需要编写读文件的迭代类就可以轻松实现文件读取：

```python
# 适用整个文件只有一行
def read_file(path):
    BLOCK_SIZE=1024
    with open(path,'rb') as f:
        with True:
            block = f.read(BLOCK_SIZE)
            if block:
                yield block
            else:
                return

fb = read_file("/var/log/messages")
for line in fb:
    print(line)
    
# 带分隔符的版本:
def read_file(f,separator):
    buf = ''
    while True:
        while separator in buf:
            position = buf.index(separator)
            yield buf[:position]
            buf = buf[psition + len(separator):]
            
        chunk = f.read(1024)
        if not chunk:
            yield buf
            break
        buf += chunk
if __name__ == '__main__':
    with open("/var/log/messages",encoding="utf-8") as f:
        for line in read_file(f,"\n"):
            print(line)
```

### 总结

- 容器是可迭代对象，可迭代对象调用 iter() 函数，可以得到一个迭代器。迭代器可以通过 next() 函数来得到下一个元素，从而支持遍历。
- 生成器是一种特殊的迭代器（反之不成立）。使用生成器，你可以写出来更加清晰的代码；合理使用生成器，可以降低内存占用、优化程序结构、提高程序速度。