---

title: 编译Hadoop支持压缩

categories:

- 大数据

tags:

---

# 编译Hadoop支持压缩

**编译hadoop支持压缩的前提条件**:

```text
1. Unix 系统(本例centos6.5)
2. JDK 1.7+ 
3. Maven 3.0 或更高版本
4. Protobuf 2.5.0
5. CMake2.6 或更高版本
6. Zlib devel
7. openssl devel
8. 能访问互联网，或者使用本地仓库(本例使用本地仓库)
```

## 



#### 安装JDK&Maven&依赖环境

```shell
###JDK&Maven
$ tar zxfv jdk-7u80-linux-x64.tar.gz -C ~/usr/java/
$ tar zxfv apache-maven-3.6.0-bin.tar.gz -C ~/app/
$ tar zxfv repo.tar.gz /* 这是我保存过的本地仓库 */ -C ~/maven_repository/
$ vi ~/app/apache-maven/conf/settings.xml
## 添加
<localRepository>/home/hadoop/maven_repository/repo</localRepository>
$ vi ~/.bash_profile
### 添加以下内容
JAVA_HOME=/usr/java/jdk1.7.0_80
MAVEN_HOME=/home/hadoop/app/apache-maven-3.6.0

export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PATH

### 环境依赖
$ yum -y install gcc gcc-c++ bzip2 bzip2-devel zlib zlib-devel lzo lzo-devel lzop autoconf automake curl curl-devel openssl openssl-devel svn ncurses-devel libtool 

```

#### 安装CMake&Protobuf&Snappy

```shell
###CMake
### CMake编译需要C++11，但是Centos6.5默认的gcc版本不支持c++11,所以先编译gcc和glibc
$ tar jxvf gcc-4.8.1.tar.bz2 -C ~/app/
$ tar jxf gmp-4.3.2.tar.bz2 
$ tar jxf mpfr-2.4.2.tar.bz2
$ tar zxf mpc-0.8.1.tar.gz
$ mv gmp-4.3.2 ~/app/gcc-4.8.1/gmp
$ mv mpfr-2.4.2 ~/app/gcc-4.8.1/mpfr
$ mv mpc-0.8.1 ~/app/gcc-4.8.1/mpc
$ cd ~/app/gcc-4.8.1/ && mkdir build && cd build
$ ../configure --prefix=/usr/local/gcc4.8.1 --enable-languages=c,c++ --enable-checking=release --disable-multilib
## --prefix是可选项,如果想保留系统原有的gcc版本，请添加这个选项
$ make -j4
$ make install
###glibc
$ tar zxfv glibc-2.14.tar.gz -C ~/app/
$ cd ~/app/glibc-2.14 && mkdir build && cd build
$ ../configure --prefix=/usr/local/glibc2.14
$ make -j4 
$ make install
$ ln -s /usr/local/lib64/libstdc++.* /usr/lib64/

### CMake
$ tar zxfv cmake-3.14.1.tar.gz -C ~/app/
$ cd ~/app/cmake-3.14.1
$ ./bootstrap && make && make install

### Protobuf
$ tar zxfv protobuf-2.5.0.tar.gz -C ~/app/
$ cd ~/app/protobuf-2.5.0/
$ ./configure --prefix=/usr/local/protobuf && make && make install
### snappy 
$ tar zxfv snappy-1.1.4.tar.gz ~/app/
$ cd ~/app/snappy-1.1.4
$ ./configure && make && make install
### 环境变量
$ vi /home/hadoop/.bash_profile
##添加
export PROTOBUF_HOME=/usr/local/protobuf
export PATH=$JAVA_HOME/bin:$MAVEN_HOME/bin:$PROTOBUF_HOME/bin:$PATH
```

#### 编译hadoop

```shell
### 下载源码包，解压
$ tar zxfv hadoop-2.6.0-cdh5.7.0-src.tar.gz -C ~/app/
$ cd ~/app/hadoop-2.6.0-cdh5.7.0
$ mvn clean package -Pdist,native -DskipTests -Dtar -Dhttps.protocols=TLSv1.2
### 在编译完成后会提示BUILD SUCCESS字样
### 编译完成后执行
$ mv ~/app/hadoop-2.6.0-cdh5.7.0/hadoop-dist/hadoop-2.6.0-cdh5.7.0.tar.gz ~/software
$ mkdir ~/app/hadoop/
$ tar zxfv ~/software/hadoop-2.6.0-cdh5.7.0.tar.gz -C ~/app/hadoop/
$ vi ~/.bash_profile
### 添加以下字段
export HADOOP_HOME=/home/hadoop/app/hadoop/hadoop2.6.0-cdh5.7.0
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:"$JAVA_HOME/bin:$MAVEN_HOME/bin:$PROTOBUF_HOME/bin:$PATH
$ source ~/.bash_profile
$ ln -s /usr/local/lib/libsnappy.so.1 /root/app/hadoop/hadoop2.6.0-cdh5.7.0/lib/native
$ hadoop checknative -a
查看五种压缩都为true就是编译成功啦
```

![](https://s2.ax1x.com/2019/04/06/AWLCin.png)









